
import { useState, useRef, useEffect } from "react";
import { toast } from "@/components/ui/use-toast";

type MessageType = "user" | "ami";
type AmiMood = "happy" | "neutral" | "thinking" | "sad" | "excited";

export interface Message {
  id: string;
  type: MessageType;
  text: string;
  timestamp: Date;
}

export function useChat() {
  const [messages, setMessages] = useState<Message[]>([
    {
      id: "1",
      type: "ami",
      text: "Xin ch√†o! M√¨nh l√† Ami. B·∫°n c·∫£m th·∫•y th·∫ø n√†o h√¥m nay?",
      timestamp: new Date(),
    },
  ]);
  const [inputText, setInputText] = useState("");
  const [amiMood, setAmiMood] = useState<AmiMood>("happy");
  const [isRecording, setIsRecording] = useState(false);
  const [isTyping, setIsTyping] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);
  const lastInteractionTimeRef = useRef<number>(Date.now());
  const inactivityTimerRef = useRef<NodeJS.Timeout | null>(null);

  // Suggested questions
  const suggestedQuestions = [
    "B·∫°n ƒëang c·∫£m th·∫•y th·∫ø n√†o?",
    "B·∫°n c√≥ mu·ªën th∆∞ gi√£n kh√¥ng?",
    "Ch√∫ng ta c√≥ th·ªÉ l√†m g√¨ ƒë·ªÉ gi√∫p b·∫°n c·∫£m th·∫•y t·ªët h∆°n?",
    "B·∫°n c√≥ th·ªÉ k·ªÉ chuy·ªán vui kh√¥ng?",
    "H√¥m nay t√¥i c·∫£m th·∫•y kh√¥ng ·ªïn",
  ];

  // Scroll to bottom when messages change
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages]);

  // Update last interaction time when user interacts
  useEffect(() => {
    const updateLastInteractionTime = () => {
      lastInteractionTimeRef.current = Date.now();
    };

    // Listen for user interactions
    window.addEventListener("click", updateLastInteractionTime);
    window.addEventListener("keydown", updateLastInteractionTime);
    window.addEventListener("mousemove", updateLastInteractionTime);
    window.addEventListener("touchstart", updateLastInteractionTime);

    return () => {
      window.removeEventListener("click", updateLastInteractionTime);
      window.removeEventListener("keydown", updateLastInteractionTime);
      window.removeEventListener("mousemove", updateLastInteractionTime);
      window.removeEventListener("touchstart", updateLastInteractionTime);
    };
  }, []);

  // Check for inactivity and send a message
  useEffect(() => {
    return () => {
      if (inactivityTimerRef.current) {
        clearInterval(inactivityTimerRef.current);
      }
    };
  }, []);

  const setupInactivityTimer = (isChatExpanded: boolean) => {
    // Clear any existing timer
    if (inactivityTimerRef.current) {
      clearInterval(inactivityTimerRef.current);
    }

    const checkInactivity = () => {
      const now = Date.now();
      const inactiveTime = now - lastInteractionTimeRef.current;
      
      // If inactive for 5 minutes (300000 ms) and chat is expanded
      if (inactiveTime > 300000 && isChatExpanded) {
        const encouragementMessages = [
          "B·∫°n v·∫´n ·ªü ƒë√≥ ch·ª©? M√¨nh lu√¥n s·∫µn s√†ng tr√≤ chuy·ªán n·∫øu b·∫°n c·∫ßn.",
          "ƒê√£ m·ªôt l√∫c r·ªìi nh·ªâ? Hy v·ªçng b·∫°n v·∫´n ·ªïn. M√¨nh v·∫´n ·ªü ƒë√¢y n·∫øu b·∫°n mu·ªën chia s·∫ª ƒëi·ªÅu g√¨.",
          "H√¥m nay c·ªßa b·∫°n th·∫ø n√†o? M√¨nh mu·ªën bi·∫øt th√™m v·ªÅ c·∫£m nh·∫≠n c·ªßa b·∫°n.",
          "B·∫°n ƒëang l√†m g√¨ v·∫≠y? M√¨nh r·∫•t mu·ªën ƒë∆∞·ª£c tr√≤ chuy·ªán c√πng b·∫°n!",
        ];
        
        const randomMessage = encouragementMessages[Math.floor(Math.random() * encouragementMessages.length)];
        
        // Add encouragement message from Ami
        const amiMessage: Message = {
          id: Date.now().toString(),
          type: "ami",
          text: randomMessage,
          timestamp: new Date(),
        };
        
        setMessages(prev => [...prev, amiMessage]);
        setAmiMood("neutral");
        
        // Reset the timer
        lastInteractionTimeRef.current = now;
      }
    };
    
    // Set up the inactivity check timer (check every minute)
    inactivityTimerRef.current = setInterval(checkInactivity, 60000);
  };

  const handleSendMessage = () => {
    if (!inputText.trim()) return;

    // Reset last interaction time
    lastInteractionTimeRef.current = Date.now();

    // Add user message
    const userMessage: Message = {
      id: Date.now().toString(),
      type: "user",
      text: inputText,
      timestamp: new Date(),
    };
    
    setMessages([...messages, userMessage]);
    setInputText("");
    
    // Simulate Ami thinking
    setAmiMood("thinking");
    setIsTyping(true);
    
    // Simulate Ami response after a delay
    setTimeout(() => {
      // Analyze sentiment (simulated)
      const lowerText = inputText.toLowerCase();
      const hasSadWords = lowerText.includes("bu·ªìn") || 
                          lowerText.includes("m·ªát") || 
                          lowerText.includes("ch√°n") ||
                          lowerText.includes("kh√≥ khƒÉn") ||
                          lowerText.includes("kh√¥ng ·ªïn");
      
      let responseText = "";
      
      if (hasSadWords) {
        responseText = "M√¨nh hi·ªÉu c·∫£m gi√°c ƒë√≥. H√£y chia s·∫ª th√™m ƒë·ªÉ m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n t·ªët h∆°n. B·∫°n c√≥ mu·ªën th·ª≠ m·ªôt s·ªë b√†i t·∫≠p th·ªü ƒë·ªÉ th∆∞ gi√£n kh√¥ng? üòä";
        setAmiMood("neutral");
        
        // Show breathing exercise suggestion
        setTimeout(() => {
          toast({
            title: "H√≠t th·ªü s√¢u",
            description: "B·∫°n c√≥ mu·ªën th·ª±c hi·ªán b√†i t·∫≠p th·ªü ƒë·ªÉ gi·∫£m cƒÉng th·∫≥ng?",
            action: (
              <button
                className="rounded bg-primary px-3 py-1 text-xs text-primary-foreground"
                onClick={handleBreathingExercise}
              >
                Th·ª≠ ngay
              </button>
            ),
          });
        }, 1000);
        
        // Send a positive image or GIF after detecting negative mood
        setTimeout(() => {
          const encouragementMessage: Message = {
            id: Date.now().toString(),
            type: "ami",
            text: "ƒê√¢y l√† h√¨nh ·∫£nh c√≥ th·ªÉ gi√∫p b·∫°n c·∫£m th·∫•y t·ªët h∆°n üåà",
            timestamp: new Date(),
          };
          
          setMessages(prev => [...prev, encouragementMessage]);
          // Note: In a real implementation, we would send an actual image here
        }, 3000);
      } else if (lowerText.includes("chuy√™n gia") || lowerText.includes("t∆∞ v·∫•n") || lowerText.includes("gi√∫p ƒë·ª°")) {
        responseText = "B·∫°n mu·ªën k·∫øt n·ªëi v·ªõi chuy√™n gia t√¢m l√Ω? M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n k·∫øt n·ªëi ngay b√¢y gi·ªù n·∫øu b·∫°n mu·ªën. Ch·ªâ c·∫ßn nh·∫•n v√†o n√∫t 'G·ªçi chuy√™n gia' b√™n d∆∞·ªõi nh√©.";
        setAmiMood("excited");
        
        setTimeout(() => {
          toast({
            title: "K·∫øt n·ªëi chuy√™n gia",
            description: "B·∫°n c√≥ mu·ªën g·ªçi video v·ªõi chuy√™n gia t√¢m l√Ω?",
            action: (
              <button
                className="rounded bg-primary px-3 py-1 text-xs text-primary-foreground"
                onClick={() => window.location.href = "/video-call"}
              >
                G·ªçi ngay
              </button>
            ),
          });
        }, 1000);
      } else {
        responseText = "C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª! M√¨nh lu√¥n ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe v√† h·ªó tr·ª£ b·∫°n. B·∫°n c√≥ ƒëi·ªÅu g√¨ kh√°c mu·ªën n√≥i v·ªõi m√¨nh kh√¥ng? üòä";
        setAmiMood("happy");
      }
      
      const amiMessage: Message = {
        id: Date.now().toString(),
        type: "ami",
        text: responseText,
        timestamp: new Date(),
      };
      
      setIsTyping(false);
      
      // Simulate Ami speaking
      setIsSpeaking(true);
      setMessages(prev => [...prev, amiMessage]);
      
      // Stop speaking after a delay based on message length
      setTimeout(() => {
        setIsSpeaking(false);
      }, responseText.length * 50);
      
    }, 1500);
  };

  const handleToggleRecording = () => {
    if (isRecording) {
      setIsRecording(false);
      // In a real app, this would process the recording and convert to text
      toast({
        title: "Voice-to-Text",
        description: "ƒê√£ chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n"
      });
      // Simulate voice to text result
      setInputText("H√¥m nay t√¥i c·∫£m th·∫•y c√≥ ch√∫t m·ªát m·ªèi, kh√¥ng bi·∫øt l√†m sao ƒë·ªÉ c·∫£m th·∫•y t·ªët h∆°n");
    } else {
      setIsRecording(true);
      toast({
        title: "ƒêang ghi √¢m",
        description: "H√£y n√≥i ƒëi·ªÅu b·∫°n mu·ªën chia s·∫ª...",
      });
    }
  };

  const handleBreathingExercise = () => {
    toast({
      title: "B√†i t·∫≠p h√≠t th·ªü",
      description: "H√≠t s√¢u trong 4 gi√¢y, gi·ªØ 4 gi√¢y, th·ªü ra trong 6 gi√¢y. L·∫∑p l·∫°i 5 l·∫ßn.",
      duration: 10000,
    });
  };

  const handleSuggestedQuestion = (question: string) => {
    setInputText(question);
    if (inputRef.current) {
      inputRef.current.focus();
    }
  };

  return {
    messages,
    inputText,
    setInputText,
    amiMood,
    isRecording,
    isTyping,
    isSpeaking,
    setIsSpeaking,
    suggestedQuestions,
    messagesEndRef,
    inputRef,
    handleSendMessage,
    handleToggleRecording,
    handleSuggestedQuestion,
    setupInactivityTimer,
  };
}
